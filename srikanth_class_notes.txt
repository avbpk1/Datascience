-- Start 28 May
axis = 0 will retrieve data column wise
axis = 1 will retrieve data row wise i.e. student wise
e.g.
marks.sum(axis=1) 
marks[::2].sum() -- alternate rows sum

argmax() will give the index/position of the element that has the max value
argmin() will give the index/position fo the element that has min value
argsort() wil give indexes of the sorting order. Not the actual values

sa = a[a.argsort()]

screen shot 56
a and b are 2 different objects which have different ids but they point to the same memory. When you slice -- u get a view.

if we wamt to get a copy and not a view
a2 = a.copy() -- will give a copy of that into a2. Each one will have its own memory location.

arrays extracted based on a boolean index and array of indexes is a copy and not a view. Unlike slicing.


universal functions -- page20 -- numpy
-- stacking and splitting -
Horizontal stacking  - 

2 x 2 -- 2 x3 -- as long as the number of rows is same then horizontal stacking is possible
vertical stacking as long as the columns are same
-- End 28 May

-- Start 27 MAy
Boolean Indexing
Boolean index and the array index should have the same number of elements
Very powerful concept

When ever boolean indexing is applied on an array -- the resultant is a vector not a corresponding array of same size. Reason is that the number of elements 
In each row , the number of elements being selected and returned couuld vary depending on the condition
as we dont have the same number of elements in each row -- hence returns a single dimension array -- vector

numpy_demo.ipynb -- class room note book

Masking 

(a > 20) & (a < 40) -- 2 boolean indexes  -- remember to use & which is the mask. In python  # a [(a > 2 and a < 8 )] -- #Anding in python does not work here

a[prime(a)] -- prime(a) is a function which is generating a list of booleans. 

Boolean indexing is a feature of numpy and panda libraries. It is not available in regular programming languages

a.mean() is a method because any thing you call with an object is a method -- a method is always called with an object

np.add(x,y) -- function. Functions are universal and are called with the package  -- important differentiation

a1 = np.arange(5)
a2 = np,arange(5)
a1 == a2 # This will compare each element of the array a1 with the corresponding element in the array a2. And returns an array of booleans
a1.__eq__(a2) -- internal represemntation of a1 == a2. 

all() or any() methods -- if all elements are True , then all wil return True. else False

(a1==a2).all() -- Every element in the first array
--Methods of ndarray
a = np.random.randint(1,100,(6,6))

-- End 27 May 


-- start 21 May
formatting options using mark down
bold , italic, monospace. Monospace is a where all characters maintain an equal space. Monospace can be defined with a back quote

Refere notes for red, yello, green, blue -- alert, warning etc boxes iusing css classes.

Image can also be put into a note book

myurl = "https://www....."
from IPython.display import Image
Image(url = myurl)
jupyter notebooks
-- enf 21 May
--- shell commands
Shell commands start with exclamation
!cd,  type etc -- demo.ipynb
--Magic Fuctions
Magic functions are of 2 types.
Line magic and cell magic
Line magic starts witjh % and takes the rest of the line as command
cell magic starts with %% and takes the rest of the cell as command
e.g. %pwd
%env
env = %env -- will give a dictionary of env variables assigned to env
%who will return al variables created so far
-- cell magic

nbviewer.jupyter.org

you can give the github url into that and the note book viewer will output the data.







-- end 21May



sTART - 17 maY
HAmming distance -- it is a % disagreement between 2 sequence values. For e.g. [1,2,3 [1,2,4] -- 33.33%
distance = hamming(user1_ratings,user2_ratings)

Other distances are Eucladian

Example provided in class is movies_recommendations. Other use cases are books

eND - 17 mAY

/opt/anaconda3/bin/jupyter-lab
https://github.com/srikanthpragada/DS_05_APR_2021

--09-Apr
Read about sample collection techniques
scipy is scientific python

Categorical -- example gender , branch - discrete values

Contionous -- E.g. Marks, Salaries

Mode is important when it is categorical

-- End 09April class

-- Start 10April

Exercise

Create 50 random numbers in the range 1 to 1000 and display lower outliers and upper outliers
-- End 10th April


Start 12-April

For Jupyter notebook viewer
Data Frame and Series
Column is like a series
df.salary.mean()  means salary is being used like a list
df['salary'].median()

In box plot, you can display outliers where as histogram, outliers arent shown
s.plot.box(showfilers=false) -- to turn of out liers from box plot
https://nbviewer.jupyter.org/github/srikanthpragada/DS_05_APR_2021/blob/master/stats/demo.ipynb

--Correlation -- to understand if there is an influence of one variable on another. For example, experience and salary
p value -- randomness in relationship -- the much lesser, the much better

coefficient -- high coefficient is a strong relationship
End - 12th April


--Start - 14April
Linear Regression
Slope is very important. 
Price = intercept + slope * size 
y=a+bX
y indicates dependent variable. x is independent variable.
Intercept is Y value when x = 0 
Example -- cab charges -- initial intercept(base price) + km * price per km

If there are more than 1 variable -- for e.g. Size, bedrooms , age

5000 per sq/ft
-100,000 for age
200,000 for additional bedroom

There is only intercept but multiple slopes
y = a + (b1 * x1) + (b2 * x2) + (b3 * x3)
Example
price = 0 + (100 * 5000) + (5  * -100000) + (3 * 200,000)

Error -- distance between the prediction and actual is called error or Residual
The goal is to adjust the slope in such a way that it is close to reality

Mean Squared Error -- MSE -- to remove sign and

Sum (MSE)/n

-- End of 14 April

-- Start of 15 April
a = np.eye(5,5) -- eye -- identity matrix -- 1 is filled in diagonal

np.linspace -- linearspace
-- End of 15 April

-- Start 16th April
Slicing is a concept in python. Spend some time understandig slicing in python

Assignment -- Mini
Take an array of 5 x 5. Fill it with random numbers and display numbers that are greater than the average of the whole array.

Python for data analysis Wes McKinney, covers Panda's and Numpy
Python Data Science Handbook Jake Vanderplas
-- End 16th April

-- Start 17-April -- Methods of Array -- Methods of ndarray
a.mean() -- is called ndarray methid
print(np.add(a,b)) -- Universal function -- it is not a method -- because u r calling it with numpy library and not method of an object. 
Method is always a function of an object and hence object.method is how it is usually called.

What if u want to sort the whole 2 dimension array? -- Assignment

numpy.org -- for full numpy documentation

-- End 17th April

-- Start 19th April - Monday --- Copy vs View

-- Start 20th April
Coefficient -- coeff.T -- transpose

X.dot(coeff). Addint 1 as one of the features and coefficient at the beginning is imp

Broadcasting -- Smaller array is broadcast to larger array to perform operations


Assignment
How many pixels have more than 100 for red? 
If red is more than 100, reduce it to 100.

-- End 20th April

-- Start -- 21st April 
Pandas -- Series and Datframes
Series is a function
Index in Series is also known as rowlabel
Index can be nonnumeric and non-unique

Elements in a series can be accessed by position also. For e,g - s[0]
Error will be returned in case the custom index is also numeric and the position given is not defined as part of the custom numeric index. To overcome use the properties loc and iloc
loc is purely based on custom index. iloc is based on position index		


In dictionary -- key is unique
In series -- index can be duplicated

Display values in a series where there is a decrease from a previous value.

ndarray means numpy array
-- End 21st April
-- Start 22nd April
Important powerful methods
--apply
marks.apply(get_grade)
equivalent function in python is map 
map(get_grade, arks) but you need to write a for loop for printing
for v in map(get_grade,marks):
print(v) 

Slicing is important topic

You cant use loc for sorting and displaying top 2.
Because the index keeps changing. loc is position based on position and hence will display in correct values
for e.g. narks.sort_values(ascending=False).loc[:3] will all values until position 3 which is all values
For index based retrieval -- use loc
For position based retrieval -- use iloc

Fill nulls with values is called Imputing the values

When ever we use [] or loc[] it uses index
iloc[] will use position
pandas.pydata.org
when u get info from data frame -- if data type is object -- it means string
df.info()
-- End 22nd April

-- Start 23rd April
Retrieiving data from data frames

-- Normal Slicing, LOC and ILOC
at, iat, loc, icloc
at and iat do not support slicing
at -- only for specific row and column and not for slicing

e.g. print(df.at[0,'marks']) -- # 1st row -- marks column value
print(df.iat[0,2]) -- #1st row, 2nd column value

df.head() -- first 5
df.tail() -- last 5
df.sample(5) -- 5 random rows
df.subject.isin['Python','Java'] -- compare with a alist of values
Exercise -- Subject not java , marks less than 50

df.where(df.marks > 80)

df.filter -- filter is for labels. Not for data but for row or column labels
df.nlargest(4,'Marks') -- pick rows with first 4 highest marks

df['name'].drop_duplicates gives an array
df['name'].unique gives series
seaborn library
-- End 23-April

-- Start 24 April
df.apply  can be used to find out not null values fy axis = 1ws. If rows are required, s[pecify axis = 1
df.applymap() -- the function is applied to all rows and columns
df.name.upper() -- retirns error - upper cannot be used on series
instead use df.name.str.upper()
KM58 VDK

tRUE MEANS FALSE, PASS MEANS FAIL
ASSIGNMENT -- Print Pass or Fail not True or False

df.drop([11,13]) will remove rows but for a new copy
df.drop([12,13],inplace=True) will remove rows from the original
axis=0 is rows. depends on function.

Assignment
Create a new csv file books, movies or something else. 10rows
-- End 24 April

-- Start 26 April
df.remane(columns = {'rollno': 'admno'}
Concatenation, Joining
pd.concate((df1,df2), ignore_index=True)

If ignore_index=True is not set, then the indexes of the original data frames are takenn

joining in data frames is by default outer index.
The inner join is based on index

pd.concat
pd.merge -- merge , merges data based on common column
df1.merge(df2,how='oter') for outer join

Grouping
df.groupby('subject') -- # data frame group by object
grouping is for summaries 

subgroup = df.groupby('subject')

use tips data to see grouping happenin on multiple numeric columns

tips.groupby('sex')[[total_bill','tip']].mean()
grouping on multiple columns is possible
pandas is not just for data science. It is also primarily
for data analysis
-- End 26 April
-- Start 27 April

Data Plotting, Wrangling and Pivot Table

summary = tips.groupby(['day','time']).index
summary = tips.groupby(['day','time']),as_index=False).sum()

get_dummies()

pd.get_dummies(tips[['smoker','day']])
also called as 1 heart/or encoding
tips.pivot_table(values = 'total_bill', index = 'day', columns='sex',aggfunc=['sum','mean'])

Binning
tips['bill_bin']=pd.cut(tips.total_bill,5)
tips[['total_bill','bill_bin']]
Binning is useful when we have outliers
Using Log is another method of removing the effect of outliers so that ML algorithms can work correctly

pd.qcut(tips['total_bill'],[0,0.25,0.75,1], labels['LQ', 'UQ','IQR'])

pivot_table.plot.bar()

latest payslip
latest bank
credit report

techmyfile
-- End 27th April

-- Start 28th April
Matplotlib is a python 2d plotting library. There is an extension to draw 3d also.

-- End 28th April 

-- Start 29th April

-- End 29th April

--Start 30 April
Swarm Plot
Categorical Plots

Distance between the point and the line is called residual
If residual is on 0, then there is a difference between predict
and actual
Heat Map 
Correlation Matrix

seaborn is better than matplotlib

--End 30 April

--04-May- Start
pickling
deployment
zhango framework
Data Science Life Cycle
Feature Engg is used in Exploratory Data Analyis
Not all features need to be used for prediction.
In this phase , you can drop certain features after analysis
--04-MAy End

--05 May Start
Classification case study -- loan_prediction.ipynb
train = pd.read("loan.csv") -- train is the data frame
train.shape() will give you rows and columns 
outout -- 623,13
train.sample(5) will give a sample data of 5 rows
train.info() -- gives info about the data -- not null etc
train.describe() more info
train[['ApplicantIncome','CoapplicantIncome']] subset of values
train
-- 05 May End

--08-May-Start
different models
--08-May-End

-- 10-May Start
Train , Validation and Test data sets in the range of 60%, 20%, 20%

Cross validation will divide the data into K-Fold . If k =4 it will split into 4 sets. For each data set, a model is created.
The advantage is -- every observation is used in training and every observation is used in testing

model = 
scores = cross_val_score(model, train, y, cv = 5)

some of the algorithms use cross validation

E.g. LogisticRegressionCV
train_test_split?

confusion matrix gives an array of true positives and true negatives
Amber
--> Ensemble Methods
Most of the competitions were won by individuals who used Ensemble algorithms

load_iris from sklearn
iris data is toy data
from sklearn.datasets import load_iris

d= load_iris()
print(d.DESCR)

X, y = load_iris(return_X_y=True)
votingclassifier.ipynb
page 68 of course material
Bagging means --  Bootstrap Aggregation
We build the same model but it will take different set of training observations
Again Model voting is done
ensemble_models.ipynb

Genie Index
--10 May End

--Start 11-May
Technique Boosting
XGBoost -- in competitions if u want to win
Gradient boosting classifier which internally uses different decision trees
Stacking
Voting classifier is different

svc and knn require scaling

test_model.ipynb -- plots and curves -- advanced classification concepts

u have to use the same tfidf

---Sentiment Analysis

Bag of words
2 types of matrices
sparse matrix, dense matrix
hotrl_reviews.ipynb
--End 11-May

-- Start 12-May
Case Study 2
car/prepare_data.ipynb
gradient decent ,  regularisation, pipeline, how to create one, Efficient ways to check multple hyper parameters. Grid search
use case

df.isin([?]).sum() -- gives counts of values in each column which have ?
Finding the price of a car
price_finder_models.ipynb

-- End 12-May
--> 14- May Start
-- Parameters are values that the model generates 
-- Hyper parameters are for e.g. k in k nearest neighbours which are used to 
--Grid search is to find best hyper parameters
--Gradient decent is to find best parameters
is sklearn -- random_state = (1 or 12 0r 100 or any value) if we have to keep random state consitent
blob_demo
matplot lib is very important for scatter plots

blob_demo.ipynb for un supevised learning
for k means - always scale data
make_moons.ipynb
DBSCAN - density based clustering -- another technique
In dbscan -- u dont mention how many clusters are required. The algorithm figures it out
-- 14 May End

--Start 15-May
Page  101
DBSCAN
eps - epsilon or radius
customer_seg.ipynb
what should be the ideal epsilon -- radius? reducing epsilon will increase clusters and increasing will reduce them

Hierarchial clustering - Aglomerative -- suitable for small clusters
, Divisive -- suitable for large clusters
cluster map
seaborn.clustermap
dendrogram using scipy
ward is a function to calc distance

kmeans -- centroid -- dont place centroids randomly

unsupervised - Association - REcommender systems
REcommender system is an example of unsupervised machine learning using association
candidate generation
-- reduces billions down to hundreds of thousands
Scoring

--Re-ranking
Recommender - system -- content based and collaborative filtering

scoring
Assignment -- Display all border points in a different colour

implicit

Recommender System - Collaborative filtering
Predict user ratings for products based on a user's similarity with other users
It may be user based or item based
item based - neighbours

-- End - 15 May
-- Start - 16May
Recommending movies in collaborative filtering
movies_cf_final.ipynb
-- go through sides and understand clustering
